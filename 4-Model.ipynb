{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.128533\teval-error:0.1516\n",
      "[1]\ttrain-error:0.115333\teval-error:0.146\n",
      "[2]\ttrain-error:0.109333\teval-error:0.1376\n",
      "[3]\ttrain-error:0.105333\teval-error:0.1364\n",
      "[4]\ttrain-error:0.096933\teval-error:0.1384\n",
      "[5]\ttrain-error:0.094667\teval-error:0.1364\n",
      "[6]\ttrain-error:0.087333\teval-error:0.1296\n",
      "[7]\ttrain-error:0.084933\teval-error:0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-error:0.078133\teval-error:0.1208\n",
      "[9]\ttrain-error:0.073733\teval-error:0.1172\n",
      "[10]\ttrain-error:0.068667\teval-error:0.116\n",
      "[11]\ttrain-error:0.064933\teval-error:0.1164\n",
      "[12]\ttrain-error:0.062267\teval-error:0.1112\n",
      "[13]\ttrain-error:0.060533\teval-error:0.1116\n",
      "[14]\ttrain-error:0.0568\teval-error:0.1112\n",
      "[15]\ttrain-error:0.0504\teval-error:0.1048\n",
      "[16]\ttrain-error:0.0492\teval-error:0.1004\n",
      "[17]\ttrain-error:0.0464\teval-error:0.1016\n",
      "[18]\ttrain-error:0.044267\teval-error:0.1028\n",
      "[19]\ttrain-error:0.043467\teval-error:0.1012\n",
      "[20]\ttrain-error:0.038667\teval-error:0.1016\n",
      "[21]\ttrain-error:0.036533\teval-error:0.1004\n",
      "[22]\ttrain-error:0.034933\teval-error:0.0996\n",
      "[23]\ttrain-error:0.033733\teval-error:0.1004\n",
      "[24]\ttrain-error:0.032533\teval-error:0.104\n",
      "[25]\ttrain-error:0.0312\teval-error:0.1032\n",
      "[26]\ttrain-error:0.0288\teval-error:0.102\n",
      "[27]\ttrain-error:0.027733\teval-error:0.1016\n",
      "[28]\ttrain-error:0.025733\teval-error:0.1004\n",
      "[29]\ttrain-error:0.0232\teval-error:0.1008\n",
      "[30]\ttrain-error:0.022933\teval-error:0.1024\n",
      "[31]\ttrain-error:0.020667\teval-error:0.0992\n",
      "[32]\ttrain-error:0.019867\teval-error:0.0992\n",
      "[33]\ttrain-error:0.019733\teval-error:0.0984\n",
      "[34]\ttrain-error:0.016933\teval-error:0.1028\n",
      "[35]\ttrain-error:0.017333\teval-error:0.1008\n",
      "[36]\ttrain-error:0.016267\teval-error:0.0988\n",
      "[37]\ttrain-error:0.0152\teval-error:0.0972\n",
      "[38]\ttrain-error:0.0148\teval-error:0.098\n",
      "[39]\ttrain-error:0.014533\teval-error:0.0972\n",
      "[40]\ttrain-error:0.013333\teval-error:0.0976\n",
      "[41]\ttrain-error:0.012533\teval-error:0.0948\n",
      "[42]\ttrain-error:0.012533\teval-error:0.0956\n",
      "[43]\ttrain-error:0.011467\teval-error:0.0948\n",
      "[44]\ttrain-error:0.0108\teval-error:0.0968\n",
      "[45]\ttrain-error:0.010933\teval-error:0.096\n",
      "[46]\ttrain-error:0.01\teval-error:0.0932\n",
      "[47]\ttrain-error:0.010267\teval-error:0.0924\n",
      "[48]\ttrain-error:0.0092\teval-error:0.0912\n",
      "[49]\ttrain-error:0.009467\teval-error:0.0912\n",
      "logloss: 0.2223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------\n",
    "# xgboostの実装\n",
    "# -----------------------------------\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 特徴量と目的変数をxgboostのデータ構造に変換する\n",
    "dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "num_round = 50\n",
    "\n",
    "# 学習の実行\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "# watchlistには学習データおよびバリデーションデータをセットする\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(dvalid)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測（二値の予測値ではなく、1である確率を出力するようにしている）\n",
    "pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.540884\teval-logloss:0.550034\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-logloss:0.452691\teval-logloss:0.471821\n",
      "[2]\ttrain-logloss:0.39482\teval-logloss:0.420259\n",
      "[3]\ttrain-logloss:0.351978\teval-logloss:0.385202\n",
      "[4]\ttrain-logloss:0.320213\teval-logloss:0.361498\n",
      "[5]\ttrain-logloss:0.29673\teval-logloss:0.344634\n",
      "[6]\ttrain-logloss:0.276105\teval-logloss:0.329003\n",
      "[7]\ttrain-logloss:0.258858\teval-logloss:0.316697\n",
      "[8]\ttrain-logloss:0.243629\teval-logloss:0.307749\n",
      "[9]\ttrain-logloss:0.231528\teval-logloss:0.300925\n",
      "[10]\ttrain-logloss:0.220163\teval-logloss:0.294131\n",
      "[11]\ttrain-logloss:0.209625\teval-logloss:0.285282\n",
      "[12]\ttrain-logloss:0.199507\teval-logloss:0.279123\n",
      "[13]\ttrain-logloss:0.193238\teval-logloss:0.276415\n",
      "[14]\ttrain-logloss:0.185473\teval-logloss:0.271543\n",
      "[15]\ttrain-logloss:0.174737\teval-logloss:0.265163\n",
      "[16]\ttrain-logloss:0.168997\teval-logloss:0.260891\n",
      "[17]\ttrain-logloss:0.163227\teval-logloss:0.25849\n",
      "[18]\ttrain-logloss:0.159501\teval-logloss:0.256912\n",
      "[19]\ttrain-logloss:0.156374\teval-logloss:0.255114\n",
      "[20]\ttrain-logloss:0.147222\teval-logloss:0.250345\n",
      "[21]\ttrain-logloss:0.142902\teval-logloss:0.247341\n",
      "[22]\ttrain-logloss:0.137821\teval-logloss:0.246117\n",
      "[23]\ttrain-logloss:0.133619\teval-logloss:0.243874\n",
      "[24]\ttrain-logloss:0.130467\teval-logloss:0.242507\n",
      "[25]\ttrain-logloss:0.126539\teval-logloss:0.240938\n",
      "[26]\ttrain-logloss:0.122679\teval-logloss:0.240048\n",
      "[27]\ttrain-logloss:0.119661\teval-logloss:0.238031\n",
      "[28]\ttrain-logloss:0.115058\teval-logloss:0.236994\n",
      "[29]\ttrain-logloss:0.110268\teval-logloss:0.236264\n",
      "[30]\ttrain-logloss:0.108272\teval-logloss:0.236213\n",
      "[31]\ttrain-logloss:0.102622\teval-logloss:0.232686\n",
      "[32]\ttrain-logloss:0.100615\teval-logloss:0.232121\n",
      "[33]\ttrain-logloss:0.09913\teval-logloss:0.231798\n",
      "[34]\ttrain-logloss:0.095822\teval-logloss:0.23184\n",
      "[35]\ttrain-logloss:0.093781\teval-logloss:0.229978\n",
      "[36]\ttrain-logloss:0.092428\teval-logloss:0.229803\n",
      "[37]\ttrain-logloss:0.089519\teval-logloss:0.229134\n",
      "[38]\ttrain-logloss:0.087322\teval-logloss:0.2287\n",
      "[39]\ttrain-logloss:0.085759\teval-logloss:0.227859\n",
      "[40]\ttrain-logloss:0.083396\teval-logloss:0.22857\n",
      "[41]\ttrain-logloss:0.081252\teval-logloss:0.226949\n",
      "[42]\ttrain-logloss:0.080268\teval-logloss:0.226455\n",
      "[43]\ttrain-logloss:0.078286\teval-logloss:0.226595\n",
      "[44]\ttrain-logloss:0.076156\teval-logloss:0.226067\n",
      "[45]\ttrain-logloss:0.075219\teval-logloss:0.224988\n",
      "[46]\ttrain-logloss:0.073133\teval-logloss:0.22316\n",
      "[47]\ttrain-logloss:0.071982\teval-logloss:0.222926\n",
      "[48]\ttrain-logloss:0.070255\teval-logloss:0.222653\n",
      "[49]\ttrain-logloss:0.069475\teval-logloss:0.222264\n",
      "[50]\ttrain-logloss:0.067254\teval-logloss:0.222274\n",
      "[51]\ttrain-logloss:0.066076\teval-logloss:0.221892\n",
      "[52]\ttrain-logloss:0.064741\teval-logloss:0.222578\n",
      "[53]\ttrain-logloss:0.06343\teval-logloss:0.222785\n",
      "[54]\ttrain-logloss:0.06259\teval-logloss:0.222803\n",
      "[55]\ttrain-logloss:0.061631\teval-logloss:0.222622\n",
      "[56]\ttrain-logloss:0.060562\teval-logloss:0.22149\n",
      "[57]\ttrain-logloss:0.058593\teval-logloss:0.22114\n",
      "[58]\ttrain-logloss:0.057962\teval-logloss:0.220926\n",
      "[59]\ttrain-logloss:0.056918\teval-logloss:0.219827\n",
      "[60]\ttrain-logloss:0.055642\teval-logloss:0.220266\n",
      "[61]\ttrain-logloss:0.055001\teval-logloss:0.220758\n",
      "[62]\ttrain-logloss:0.053926\teval-logloss:0.220377\n",
      "[63]\ttrain-logloss:0.053389\teval-logloss:0.22014\n",
      "[64]\ttrain-logloss:0.052521\teval-logloss:0.219513\n",
      "[65]\ttrain-logloss:0.050961\teval-logloss:0.217595\n",
      "[66]\ttrain-logloss:0.050045\teval-logloss:0.217166\n",
      "[67]\ttrain-logloss:0.049089\teval-logloss:0.216988\n",
      "[68]\ttrain-logloss:0.048196\teval-logloss:0.216233\n",
      "[69]\ttrain-logloss:0.047253\teval-logloss:0.215409\n",
      "[70]\ttrain-logloss:0.04671\teval-logloss:0.215588\n",
      "[71]\ttrain-logloss:0.045747\teval-logloss:0.215411\n",
      "[72]\ttrain-logloss:0.044629\teval-logloss:0.214068\n",
      "[73]\ttrain-logloss:0.044048\teval-logloss:0.213968\n",
      "[74]\ttrain-logloss:0.043008\teval-logloss:0.214959\n",
      "[75]\ttrain-logloss:0.042618\teval-logloss:0.215537\n",
      "[76]\ttrain-logloss:0.042185\teval-logloss:0.21631\n",
      "[77]\ttrain-logloss:0.041566\teval-logloss:0.215793\n",
      "[78]\ttrain-logloss:0.040765\teval-logloss:0.215915\n",
      "[79]\ttrain-logloss:0.040025\teval-logloss:0.216056\n",
      "[80]\ttrain-logloss:0.039717\teval-logloss:0.216423\n",
      "[81]\ttrain-logloss:0.038736\teval-logloss:0.215281\n",
      "[82]\ttrain-logloss:0.03837\teval-logloss:0.216057\n",
      "[83]\ttrain-logloss:0.038065\teval-logloss:0.215927\n",
      "[84]\ttrain-logloss:0.037374\teval-logloss:0.216652\n",
      "[85]\ttrain-logloss:0.036687\teval-logloss:0.217843\n",
      "[86]\ttrain-logloss:0.035757\teval-logloss:0.219184\n",
      "[87]\ttrain-logloss:0.035533\teval-logloss:0.219122\n",
      "[88]\ttrain-logloss:0.034801\teval-logloss:0.219667\n",
      "[89]\ttrain-logloss:0.034249\teval-logloss:0.21976\n",
      "[90]\ttrain-logloss:0.034018\teval-logloss:0.219961\n",
      "[91]\ttrain-logloss:0.033418\teval-logloss:0.219719\n",
      "[92]\ttrain-logloss:0.032483\teval-logloss:0.21991\n",
      "[93]\ttrain-logloss:0.031948\teval-logloss:0.219616\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-logloss:0.044048\teval-logloss:0.213968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------\n",
    "# 学習データとバリデーションデータのスコアのモニタリング\n",
    "# -----------------------------------\n",
    "# モニタリングをloglossで行い、アーリーストッピングの観察するroundを20とする\n",
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71,\n",
    "          'eval_metric': 'logloss'}\n",
    "num_round = 500\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist,\n",
    "                  early_stopping_rounds=20)\n",
    "\n",
    "# 最適な決定木の本数で予測を行う\n",
    "pred = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['medical_info_b2', 'medical_info_b3', 'product']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[1]\ttrain's binary_logloss: 0.454286\tvalid's binary_logloss: 0.4654\n",
      "[2]\ttrain's binary_logloss: 0.429348\tvalid's binary_logloss: 0.443537\n",
      "[3]\ttrain's binary_logloss: 0.409269\tvalid's binary_logloss: 0.425588\n",
      "[4]\ttrain's binary_logloss: 0.393109\tvalid's binary_logloss: 0.411213\n",
      "[5]\ttrain's binary_logloss: 0.379351\tvalid's binary_logloss: 0.399341\n",
      "[6]\ttrain's binary_logloss: 0.366138\tvalid's binary_logloss: 0.389055\n",
      "[7]\ttrain's binary_logloss: 0.35417\tvalid's binary_logloss: 0.378254\n",
      "[8]\ttrain's binary_logloss: 0.343782\tvalid's binary_logloss: 0.370131\n",
      "[9]\ttrain's binary_logloss: 0.334283\tvalid's binary_logloss: 0.362036\n",
      "[10]\ttrain's binary_logloss: 0.324802\tvalid's binary_logloss: 0.353452\n",
      "[11]\ttrain's binary_logloss: 0.316592\tvalid's binary_logloss: 0.346904\n",
      "[12]\ttrain's binary_logloss: 0.308484\tvalid's binary_logloss: 0.340248\n",
      "[13]\ttrain's binary_logloss: 0.301468\tvalid's binary_logloss: 0.335801\n",
      "[14]\ttrain's binary_logloss: 0.294674\tvalid's binary_logloss: 0.330487\n",
      "[15]\ttrain's binary_logloss: 0.288251\tvalid's binary_logloss: 0.325634\n",
      "[16]\ttrain's binary_logloss: 0.282225\tvalid's binary_logloss: 0.321448\n",
      "[17]\ttrain's binary_logloss: 0.277045\tvalid's binary_logloss: 0.318027\n",
      "[18]\ttrain's binary_logloss: 0.271694\tvalid's binary_logloss: 0.31501\n",
      "[19]\ttrain's binary_logloss: 0.265931\tvalid's binary_logloss: 0.311018\n",
      "[20]\ttrain's binary_logloss: 0.261148\tvalid's binary_logloss: 0.307548\n",
      "[21]\ttrain's binary_logloss: 0.255397\tvalid's binary_logloss: 0.30346\n",
      "[22]\ttrain's binary_logloss: 0.25054\tvalid's binary_logloss: 0.299063\n",
      "[23]\ttrain's binary_logloss: 0.245472\tvalid's binary_logloss: 0.295614\n",
      "[24]\ttrain's binary_logloss: 0.241049\tvalid's binary_logloss: 0.292596\n",
      "[25]\ttrain's binary_logloss: 0.237346\tvalid's binary_logloss: 0.289802\n",
      "[26]\ttrain's binary_logloss: 0.233644\tvalid's binary_logloss: 0.287015\n",
      "[27]\ttrain's binary_logloss: 0.229771\tvalid's binary_logloss: 0.285147\n",
      "[28]\ttrain's binary_logloss: 0.225304\tvalid's binary_logloss: 0.281868\n",
      "[29]\ttrain's binary_logloss: 0.221761\tvalid's binary_logloss: 0.279715\n",
      "[30]\ttrain's binary_logloss: 0.218152\tvalid's binary_logloss: 0.276755\n",
      "[31]\ttrain's binary_logloss: 0.214731\tvalid's binary_logloss: 0.274906\n",
      "[32]\ttrain's binary_logloss: 0.21187\tvalid's binary_logloss: 0.273533\n",
      "[33]\ttrain's binary_logloss: 0.208913\tvalid's binary_logloss: 0.271975\n",
      "[34]\ttrain's binary_logloss: 0.205932\tvalid's binary_logloss: 0.269754\n",
      "[35]\ttrain's binary_logloss: 0.20259\tvalid's binary_logloss: 0.267191\n",
      "[36]\ttrain's binary_logloss: 0.199625\tvalid's binary_logloss: 0.265015\n",
      "[37]\ttrain's binary_logloss: 0.197027\tvalid's binary_logloss: 0.264288\n",
      "[38]\ttrain's binary_logloss: 0.193946\tvalid's binary_logloss: 0.263265\n",
      "[39]\ttrain's binary_logloss: 0.191536\tvalid's binary_logloss: 0.262294\n",
      "[40]\ttrain's binary_logloss: 0.188342\tvalid's binary_logloss: 0.259765\n",
      "[41]\ttrain's binary_logloss: 0.185896\tvalid's binary_logloss: 0.257982\n",
      "[42]\ttrain's binary_logloss: 0.183334\tvalid's binary_logloss: 0.257238\n",
      "[43]\ttrain's binary_logloss: 0.181354\tvalid's binary_logloss: 0.256282\n",
      "[44]\ttrain's binary_logloss: 0.17922\tvalid's binary_logloss: 0.255055\n",
      "[45]\ttrain's binary_logloss: 0.176956\tvalid's binary_logloss: 0.253577\n",
      "[46]\ttrain's binary_logloss: 0.174588\tvalid's binary_logloss: 0.252098\n",
      "[47]\ttrain's binary_logloss: 0.172249\tvalid's binary_logloss: 0.250808\n",
      "[48]\ttrain's binary_logloss: 0.169526\tvalid's binary_logloss: 0.249644\n",
      "[49]\ttrain's binary_logloss: 0.167526\tvalid's binary_logloss: 0.24889\n",
      "[50]\ttrain's binary_logloss: 0.16545\tvalid's binary_logloss: 0.24807\n",
      "[51]\ttrain's binary_logloss: 0.162881\tvalid's binary_logloss: 0.245714\n",
      "[52]\ttrain's binary_logloss: 0.160862\tvalid's binary_logloss: 0.24506\n",
      "[53]\ttrain's binary_logloss: 0.158953\tvalid's binary_logloss: 0.244376\n",
      "[54]\ttrain's binary_logloss: 0.15685\tvalid's binary_logloss: 0.242814\n",
      "[55]\ttrain's binary_logloss: 0.155006\tvalid's binary_logloss: 0.241794\n",
      "[56]\ttrain's binary_logloss: 0.152759\tvalid's binary_logloss: 0.240173\n",
      "[57]\ttrain's binary_logloss: 0.150735\tvalid's binary_logloss: 0.239338\n",
      "[58]\ttrain's binary_logloss: 0.149108\tvalid's binary_logloss: 0.238941\n",
      "[59]\ttrain's binary_logloss: 0.147209\tvalid's binary_logloss: 0.238182\n",
      "[60]\ttrain's binary_logloss: 0.145662\tvalid's binary_logloss: 0.237785\n",
      "[61]\ttrain's binary_logloss: 0.143415\tvalid's binary_logloss: 0.236284\n",
      "[62]\ttrain's binary_logloss: 0.141762\tvalid's binary_logloss: 0.23558\n",
      "[63]\ttrain's binary_logloss: 0.140409\tvalid's binary_logloss: 0.235289\n",
      "[64]\ttrain's binary_logloss: 0.138893\tvalid's binary_logloss: 0.234525\n",
      "[65]\ttrain's binary_logloss: 0.137423\tvalid's binary_logloss: 0.234159\n",
      "[66]\ttrain's binary_logloss: 0.13595\tvalid's binary_logloss: 0.233513\n",
      "[67]\ttrain's binary_logloss: 0.134412\tvalid's binary_logloss: 0.232994\n",
      "[68]\ttrain's binary_logloss: 0.132967\tvalid's binary_logloss: 0.232634\n",
      "[69]\ttrain's binary_logloss: 0.131473\tvalid's binary_logloss: 0.231926\n",
      "[70]\ttrain's binary_logloss: 0.129883\tvalid's binary_logloss: 0.230888\n",
      "[71]\ttrain's binary_logloss: 0.128601\tvalid's binary_logloss: 0.230392\n",
      "[72]\ttrain's binary_logloss: 0.126664\tvalid's binary_logloss: 0.229085\n",
      "[73]\ttrain's binary_logloss: 0.125221\tvalid's binary_logloss: 0.228812\n",
      "[74]\ttrain's binary_logloss: 0.123835\tvalid's binary_logloss: 0.228386\n",
      "[75]\ttrain's binary_logloss: 0.122624\tvalid's binary_logloss: 0.227671\n",
      "[76]\ttrain's binary_logloss: 0.121111\tvalid's binary_logloss: 0.226936\n",
      "[77]\ttrain's binary_logloss: 0.119972\tvalid's binary_logloss: 0.226386\n",
      "[78]\ttrain's binary_logloss: 0.118846\tvalid's binary_logloss: 0.226546\n",
      "[79]\ttrain's binary_logloss: 0.117853\tvalid's binary_logloss: 0.226293\n",
      "[80]\ttrain's binary_logloss: 0.116445\tvalid's binary_logloss: 0.225336\n",
      "[81]\ttrain's binary_logloss: 0.114972\tvalid's binary_logloss: 0.224775\n",
      "[82]\ttrain's binary_logloss: 0.113891\tvalid's binary_logloss: 0.224523\n",
      "[83]\ttrain's binary_logloss: 0.112694\tvalid's binary_logloss: 0.224459\n",
      "[84]\ttrain's binary_logloss: 0.111511\tvalid's binary_logloss: 0.223836\n",
      "[85]\ttrain's binary_logloss: 0.110331\tvalid's binary_logloss: 0.223431\n",
      "[86]\ttrain's binary_logloss: 0.108975\tvalid's binary_logloss: 0.222701\n",
      "[87]\ttrain's binary_logloss: 0.107753\tvalid's binary_logloss: 0.221952\n",
      "[88]\ttrain's binary_logloss: 0.106266\tvalid's binary_logloss: 0.220822\n",
      "[89]\ttrain's binary_logloss: 0.105333\tvalid's binary_logloss: 0.220196\n",
      "[90]\ttrain's binary_logloss: 0.104252\tvalid's binary_logloss: 0.21966\n",
      "[91]\ttrain's binary_logloss: 0.103194\tvalid's binary_logloss: 0.219586\n",
      "[92]\ttrain's binary_logloss: 0.102277\tvalid's binary_logloss: 0.2194\n",
      "[93]\ttrain's binary_logloss: 0.101037\tvalid's binary_logloss: 0.218694\n",
      "[94]\ttrain's binary_logloss: 0.100107\tvalid's binary_logloss: 0.219007\n",
      "[95]\ttrain's binary_logloss: 0.0991938\tvalid's binary_logloss: 0.218588\n",
      "[96]\ttrain's binary_logloss: 0.0980778\tvalid's binary_logloss: 0.217905\n",
      "[97]\ttrain's binary_logloss: 0.0971554\tvalid's binary_logloss: 0.217729\n",
      "[98]\ttrain's binary_logloss: 0.0961875\tvalid's binary_logloss: 0.21756\n",
      "[99]\ttrain's binary_logloss: 0.0953092\tvalid's binary_logloss: 0.217168\n",
      "[100]\ttrain's binary_logloss: 0.0942369\tvalid's binary_logloss: 0.216144\n",
      "logloss: 0.2161\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# lightgbmの実装\n",
    "# -----------------------------------\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 特徴量と目的変数をlightgbmのデータ構造に変換する\n",
    "lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "params = {'objective': 'binary', 'seed': 71, 'verbose': 0, 'metrics': 'binary_logloss'}\n",
    "num_round = 100\n",
    "\n",
    "# 学習の実行\n",
    "# カテゴリ変数をパラメータで指定している\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "categorical_features = ['product', 'medical_info_b2', 'medical_info_b3']\n",
    "model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                  categorical_feature=categorical_features,\n",
    "                  valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval])\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/b0/efabbd6765f0d7c27ae8671b98dcdc8eb04f3104c580edd2f03501a0d527/lightgbm-3.0.0-py2.py3-none-win_amd64.whl (737kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.17.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
